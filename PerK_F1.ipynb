{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import torch.utils.data\n",
    "from torch.backends import cudnn\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import bottleneck as bn\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from Utils.utils import *\n",
    "from Utils.models import *\n",
    "from Utils.calibration import *\n",
    "\n",
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "dataset = 'ml10m20'\n",
    "\n",
    "train_pair = np.load('data/'+dataset+'/train.npy', allow_pickle=True)\n",
    "train_dic = np.load('data/'+dataset+'/train_dic.npy', allow_pickle=True).item()\n",
    "val_dic = np.load('data/'+dataset+'/val_dic.npy', allow_pickle=True).item()\n",
    "trainval_dic = np.load('data/'+dataset+'/trainval_dic.npy', allow_pickle=True).item()\n",
    "test_dic = np.load('data/'+dataset+'/test_dic.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69838 8939\n",
      "(5991023, 2)\n"
     ]
    }
   ],
   "source": [
    "num_user = train_pair[:,0].max() + 1\n",
    "num_item = int(max(train_pair[:,1].max(), max(np.concatenate([a for a in val_dic.values()])), max(np.concatenate([a for a in test_dic.values()])))) + 1\n",
    "print(num_user, num_item)\n",
    "print(train_pair.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69838,) (69838,)\n",
      "[1.335  1.3382 0.4524 ... 0.8853 1.3133 1.1053] [-13.5562 -14.2873  -7.187  ...  -7.8323 -14.7685 -10.578 ]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('model/BPR_'+dataset, map_location = 'cuda:'+str(gpu))\n",
    "\n",
    "Platt_a = np.load('model/A_BPR_'+dataset+'.npy')\n",
    "Platt_b = np.load('model/B_BPR_'+dataset+'.npy')\n",
    "print(Platt_a.shape, Platt_b.shape)\n",
    "print(Platt_a, Platt_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG=[[0.     0.     0.     ... 0.4272 0.4272 0.4272]\n",
      " [1.     0.6131 0.7039 ... 0.7616 0.7616 0.7616]\n",
      " [0.     0.3869 0.2961 ... 0.1734 0.1734 0.1734]\n",
      " ...\n",
      " [0.     0.     0.     ... 0.2389 0.2389 0.2389]\n",
      " [1.     0.6131 0.4693 ... 0.5224 0.5224 0.5224]\n",
      " [1.     1.     1.     ... 0.6011 0.6011 0.6011]], HR=[[0.     0.     0.     ... 1.     1.     1.    ]\n",
      " [1.     0.5    0.6667 ... 1.     1.     1.    ]\n",
      " [0.     0.5    0.3333 ... 0.1429 0.1429 0.1429]\n",
      " ...\n",
      " [0.     0.     0.     ... 0.3103 0.3103 0.3103]\n",
      " [1.     0.5    0.3333 ... 0.6    0.6    0.6   ]\n",
      " [1.     1.     1.     ... 0.5455 0.5455 0.5455]], F1=[[0.     0.     0.     ... 0.1538 0.1509 0.1481]\n",
      " [0.4    0.3333 0.5714 ... 0.1538 0.1509 0.1481]\n",
      " [0.     0.2222 0.2    ... 0.0364 0.0357 0.0351]\n",
      " ...\n",
      " [0.     0.     0.     ... 0.2338 0.2308 0.2278]\n",
      " [0.1818 0.1667 0.1538 ... 0.2069 0.2034 0.2   ]\n",
      " [0.1667 0.3077 0.4286 ... 0.2034 0.2    0.1967]], time =3.59, 3.14\n"
     ]
    }
   ],
   "source": [
    "N=50\n",
    "\n",
    "## test\n",
    "t0 = time.time()\n",
    "val_loader = torch.utils.data.DataLoader(np.arange(num_user), batch_size=50)\n",
    "with torch.no_grad():                \n",
    "    model.eval()\n",
    "    topk_matrix = np.zeros((num_user, N))\n",
    "    topk_score_matrix = np.zeros((num_user, N))\n",
    "    topk_idx_matrix = np.zeros((num_user, N))\n",
    "\n",
    "    for us in val_loader:\n",
    "        ## inference\n",
    "        us_c = us.cuda(gpu)\n",
    "        t1 = time.time()\n",
    "        row = model.forward_eval(us_c)\n",
    "        for idx, u in enumerate(us): # do not recommend interacted items\n",
    "            row[idx][trainval_dic[u.numpy().item()]] = float('-inf')\n",
    "            \n",
    "        ## ranking (sorting)\n",
    "        topk_score, topk_idx = torch.topk(row, N)\n",
    "        topk_score_matrix[us] = topk_score.cpu()\n",
    "        topk_idx_matrix[us] = topk_idx.cpu()\n",
    "\n",
    "        ## boolean matrix (|U| * N)\n",
    "        interactions = torch.zeros([us.size()[0], num_item], dtype=torch.bool, device=gpu)\n",
    "        users_t, items_t = [], []\n",
    "        for idx, u in enumerate(us):\n",
    "            u = u.cpu().numpy().item()\n",
    "            for i in test_dic[u]:\n",
    "                users_t.append(idx)\n",
    "                items_t.append(i)        \n",
    "        interactions[users_t, items_t] = True        \n",
    "        y_sorted = interactions.gather(-1, topk_idx)\n",
    "        \n",
    "        topk_matrix[us] = y_sorted.cpu().numpy()\n",
    "t_rec = time.time() ##\n",
    "\n",
    "NDCG, HR, F1 = evaluate(range(1,N+1), topk_matrix, test_dic, num_item, reduce=False)\n",
    "t_eval = time.time() ##\n",
    "\n",
    "print('NDCG={}, HR={}, F1={}, time ={:.2f}, {:.2f}'.format(NDCG, HR, F1, t_rec-t0, t_eval-t_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0546, 0.0912, 0.118 , 0.1384, 0.1541, 0.1667, 0.1769, 0.1853, 0.1923, 0.1984,\n",
       "       0.2032, 0.2073, 0.2105, 0.2133, 0.2157, 0.2178, 0.2194, 0.2207, 0.2219, 0.2228,\n",
       "       0.2234, 0.224 , 0.2243, 0.2244, 0.2245, 0.2245, 0.2245, 0.2244, 0.2241, 0.2239,\n",
       "       0.2236, 0.2231, 0.2226, 0.222 , 0.2215, 0.221 , 0.2204, 0.2198, 0.2192, 0.2186,\n",
       "       0.2179, 0.2172, 0.2166, 0.2159, 0.2152, 0.2145, 0.2138, 0.2132, 0.2125, 0.2117])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(F1, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PerK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wonbin/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:836: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.640133380889893\n",
      "(69838, 3000)\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "132.81352043151855\n",
      "PerK F1: 0.2538\n"
     ]
    }
   ],
   "source": [
    "M = 3000 ## ml10m20\n",
    "\n",
    "t0 = time.time()\n",
    "val_loader = torch.utils.data.DataLoader(np.arange(num_user), batch_size=50)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    all_sum_matrix_t = np.zeros(num_user)\n",
    "    val_sum_matrix_t = np.zeros(num_user)\n",
    "    topk_matrix_t = np.zeros((num_user, M))\n",
    "    topk_score_matrix = np.zeros((num_user, M))\n",
    "    topk_idx_matrix = np.zeros((num_user, M))\n",
    "\n",
    "    for us in val_loader:\n",
    "        ## inference\n",
    "        row = model.forward_eval(us.cuda(gpu))\n",
    "        for idx, u in enumerate(us): # do not recommend interacted items\n",
    "            user = u.numpy().item()\n",
    "            val_score = row[idx][val_dic[user]]\n",
    "            val_sum_matrix_t[user] = torch.sigmoid(torch.mul(val_score, torch.FloatTensor(Platt_a).cuda(gpu)[user]) + torch.FloatTensor(Platt_b).cuda(gpu)[user]).sum().cpu().numpy()\n",
    "            row[idx][trainval_dic[user]] = float('-inf')\n",
    "\n",
    "        ## ranking (sorting)\n",
    "        all_sum_matrix_t[us] = torch.sigmoid(torch.mul(row, torch.FloatTensor(Platt_a).cuda(gpu)[us].resize(len(us), 1)) + torch.FloatTensor(Platt_b).cuda(gpu)[us].resize(len(us), 1)).sum(dim=1).cpu().numpy()\n",
    "\n",
    "        topk_score, topk_idx = torch.topk(row, M)\n",
    "        topk_score_matrix[us] = topk_score.cpu()\n",
    "        topk_idx_matrix[us] = topk_idx.cpu()\n",
    "\n",
    "        ## boolean matrix (|U| * N)\n",
    "        interactions = torch.zeros([us.size()[0], num_item], dtype=torch.bool, device=gpu)\n",
    "        users_t, items_t = [], []\n",
    "        for idx, u in enumerate(us):\n",
    "            u = u.cpu().numpy().item()\n",
    "            for i in test_dic[u]:\n",
    "                users_t.append(idx)\n",
    "                items_t.append(i)        \n",
    "        interactions[users_t, items_t] = True\n",
    "        y_sorted = interactions.gather(-1, topk_idx)\n",
    "\n",
    "        topk_matrix_t[us] = y_sorted.cpu().numpy()\n",
    "        \n",
    "topk_score_matrix = torch.FloatTensor(topk_score_matrix).cuda(gpu)\n",
    "NN = num_user\n",
    "topk_prob_matrix_t = torch.sigmoid(torch.mul(topk_score_matrix, torch.FloatTensor(Platt_a).cuda(gpu)[:NN].resize(NN, 1)) + torch.FloatTensor(Platt_b).cuda(gpu)[:NN].resize(NN, 1))\n",
    "topk_prob_matrix_t = topk_prob_matrix_t.cpu().numpy()[:, :M]\n",
    "\n",
    "K = M\n",
    "ratio_t_K = (topk_prob_matrix_t[:, :K].sum(axis=1) + val_sum_matrix_t) / topk_prob_matrix_t[:, :K].sum(axis=1)\n",
    "\n",
    "topk_prob_matrix_s = topk_prob_matrix_t * ratio_t_K.reshape(-1, 1)\n",
    "print(time.time() - t0)\n",
    "\n",
    "### F1\n",
    "k = M\n",
    "S = M\n",
    "topk_prob_matrix = topk_prob_matrix_s[:, :k]\n",
    "print(topk_prob_matrix.shape)\n",
    "\n",
    "Mom_mat = [np.array([(k+s) for s in range(1, S+1)]) for k in range(1,N+1)]\n",
    "\n",
    "F1_mat = np.zeros((num_user, N))\n",
    "t0 = time.time()\n",
    "for u in range(NN):\n",
    "    if u % 10000 == 0:\n",
    "        print(u)\n",
    "    prob = topk_prob_matrix[u]\n",
    "\n",
    "    F1_S = np.zeros((N, S))\n",
    "    prob_sum = np.diff(PB_CDF_RNA(prob, np.arange(-1, S))) # (S) vector\n",
    "    for i in range(N):\n",
    "        F1_S[i] = 2 * prob_sum * prob[i]\n",
    "\n",
    "    F1_u = np.cumsum(F1_S, axis=0) # (N * S)\n",
    "    F1_mat[u] = np.array([np.sum(F1_u[k] / Mom_mat[k]) for k in range(N)])\n",
    "\n",
    "## PerK\n",
    "NNN = NN #NN\n",
    "th_pred = []\n",
    "for idx, F1_u in enumerate(F1_mat):\n",
    "    if F1[idx].sum() == 0:\n",
    "        th_pred.append(-1)\n",
    "    else:\n",
    "        th_max = np.argmax(F1_u)\n",
    "        th_pred.append(th_max + 1)\n",
    "print(time.time() - t0)\n",
    "\n",
    "F1_perk = []\n",
    "for idx, HR_u in enumerate(F1):\n",
    "    if th_pred[idx] == -1:\n",
    "        F1_perk.append(HR_u[0])\n",
    "\n",
    "    else:\n",
    "        F1_perk.append(HR_u[th_pred[idx]-1])\n",
    "\n",
    "## Greedy-K train\n",
    "print('PerK F1: {:.4f}'.format(np.mean(F1_perk)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
